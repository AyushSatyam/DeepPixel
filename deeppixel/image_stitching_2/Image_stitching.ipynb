{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_stitching.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-zS614BNQD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip uninstall opencv-python -y\n",
        "# downgrade OpenCV a bit since some none-free features are not avilable\n",
        "!pip install opencv-contrib-python==3.4.2.17 --force-reinstall"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpYcUd9DXTAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import sys\n",
        "import time\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmCu4BhwwC0S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class matchers:\n",
        "\tdef __init__(self):\n",
        "\t\tself.surf = cv2.xfeatures2d.SURF_create()\n",
        "\t\tFLANN_INDEX_KDTREE = 0\n",
        "\t\tindex_params = dict(algorithm=0, trees=5)\n",
        "\t\tsearch_params = dict(checks=50)\n",
        "\t\tself.flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "\n",
        "\tdef match(self, i1, i2, direction=None):\n",
        "\t\timageSet1 = self.getSURFFeatures(i1)\n",
        "\t\timageSet2 = self.getSURFFeatures(i2)\n",
        "\t#\tprint (\"Direction : \", direction)\n",
        "\t\tmatches = self.flann.knnMatch(\n",
        "\t\t\timageSet2['des'],\n",
        "\t\t\timageSet1['des'],\n",
        "\t\t\tk=2\n",
        "\t\t\t)\n",
        "\t\tgood = []\n",
        "\t\tfor i , (m, n) in enumerate(matches):\n",
        "\t\t\tif m.distance < 0.7*n.distance:\n",
        "\t\t\t\tgood.append((m.trainIdx, m.queryIdx))\n",
        "\n",
        "\t\tif len(good) > 4:\n",
        "\t\t\tpointsCurrent = imageSet2['kp']\n",
        "\t\t\tpointsPrevious = imageSet1['kp']\n",
        "\n",
        "\t\t\tmatchedPointsCurrent = np.float32(\n",
        "\t\t\t\t[pointsCurrent[i].pt for (__, i) in good]\n",
        "\t\t\t)\n",
        "\t\t\tmatchedPointsPrev = np.float32(\n",
        "\t\t\t\t[pointsPrevious[i].pt for (i, __) in good]\n",
        "\t\t\t\t)\n",
        "\n",
        "\t\t\tH, s = cv2.findHomography(matchedPointsCurrent, matchedPointsPrev, cv2.RANSAC, 4)\n",
        "\t\t\treturn H\n",
        "\t\treturn None\n",
        "\n",
        "\tdef getSURFFeatures(self, im):\n",
        "\t\tgray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
        "\t\tkp, des = self.surf.detectAndCompute(gray, None)\n",
        "\t\treturn {'kp':kp, 'des':des}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxxSxglbwfPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Stitch:\n",
        "\tdef __init__(self, args):\n",
        "\t\tself.path = args\n",
        "\t\tfp = open(self.path, 'r')\n",
        "\t\tfilenames = [each.rstrip('\\r\\n') for each in  fp.readlines()]\n",
        "\t\t#print (filenames)\n",
        "\t\tself.images = [cv2.resize(cv2.imread(each),(480, 320)) for each in filenames]\n",
        "\t\tself.count = len(self.images)\n",
        "\t\tself.left_list, self.right_list, self.center_im = [], [],None\n",
        "\t\tself.matcher_obj = matchers()\n",
        "\t\tself.prepare_lists()\n",
        "\n",
        "\tdef prepare_lists(self):\n",
        "\t\t#print (\"Number of images : %d\"%self.count)\n",
        "\t\tself.centerIdx = self.count/2 \n",
        "\t\t#print (\"Center index image : %d\"%self.centerIdx)\n",
        "\t\tself.center_im = self.images[int(self.centerIdx)]\n",
        "\t\tfor i in range(self.count):\n",
        "\t\t\tif(i<=self.centerIdx):\n",
        "\t\t\t\tself.left_list.append(self.images[i])\n",
        "\t\t\telse:\n",
        "\t\t\t\tself.right_list.append(self.images[i])\n",
        "\t\t#print (\"Image lists prepared\")\n",
        "\n",
        "\tdef leftshift(self):\n",
        "\t\t# self.left_list = reversed(self.left_list)\n",
        "\t\ta = self.left_list[0]\n",
        "\t\tfor b in self.left_list[1:]:\n",
        "\t\t\tH = self.matcher_obj.match(a, b, 'left')\n",
        "\t\t\t#print (\"Homography is : \", H)\n",
        "\t\t\txh = np.linalg.inv(H)\n",
        "\t\t\t#print (\"Inverse Homography :\", xh)\n",
        "\t\t\tds = np.dot(xh, np.array([a.shape[1], a.shape[0], 1]));\n",
        "\t\t\tds = ds/ds[-1]\n",
        "\t\t\t#print (\"final ds=>\", ds)\n",
        "\t\t\tf1 = np.dot(xh, np.array([0,0,1]))\n",
        "\t\t\tf1 = f1/f1[-1]\n",
        "\t\t\txh[0][-1] += abs(f1[0])\n",
        "\t\t\txh[1][-1] += abs(f1[1])\n",
        "\t\t\tds = np.dot(xh, np.array([a.shape[1], a.shape[0], 1]))\n",
        "\t\t\toffsety = abs(int(f1[1]))\n",
        "\t\t\toffsetx = abs(int(f1[0]))\n",
        "\t\t\tdsize = (int(ds[0])+offsetx, int(ds[1]) + offsety)\n",
        "\t\t\t#print (\"image dsize =>\", dsize)\n",
        "\t\t\ttmp = cv2.warpPerspective(a, xh, dsize)\n",
        "\t\t\t# cv2.imshow(\"warped\", tmp)\n",
        "\t\t\t# cv2.waitKey()\n",
        "\t\t\ttmp[offsety:b.shape[0]+offsety, offsetx:b.shape[1]+offsetx] = b\n",
        "\t\t\ta = tmp\n",
        "\n",
        "\t\tself.leftImage = tmp\n",
        "\n",
        "\t\t\n",
        "\tdef rightshift(self):\n",
        "\t\tfor each in self.right_list:\n",
        "\t\t\tH = self.matcher_obj.match(self.leftImage, each, 'right')\n",
        "\t\t\t#print (\"Homography :\", H)\n",
        "\t\t\ttxyz = np.dot(H, np.array([each.shape[1], each.shape[0], 1]))\n",
        "\t\t\ttxyz = txyz/txyz[-1]\n",
        "\t\t\tdsize = (int(txyz[0])+self.leftImage.shape[1], int(txyz[1])+self.leftImage.shape[0])\n",
        "\t\t\ttmp = cv2.warpPerspective(each, H, dsize)\n",
        "\t\t\t#plt.imshow(tmp)\n",
        "\t\t\t#cv2.waitKey()\n",
        "\t\t\t# tmp[:self.leftImage.shape[0], :self.leftImage.shape[1]]=self.leftImage\n",
        "\t\t\ttmp = self.mix_and_match(self.leftImage, tmp)\n",
        "\t\t\t#print (\"tmp shape\",tmp.shape)\n",
        "\t\t\t#print (\"self.leftimage shape=\", self.leftImage.shape)\n",
        "\t\t\tself.leftImage = tmp\n",
        "\t\t# self.showImage('left')\n",
        "\n",
        "\n",
        "\n",
        "\tdef mix_and_match(self, leftImage, warpedImage):\n",
        "\t\ti1y, i1x = leftImage.shape[:2]\n",
        "\t\ti2y, i2x = warpedImage.shape[:2]\n",
        "\t\t#print (leftImage[-1,-1])\n",
        "\n",
        "\t\tt = time.time()\n",
        "\t\tblack_l = np.where(leftImage == np.array([0,0,0]))\n",
        "\t\tblack_wi = np.where(warpedImage == np.array([0,0,0]))\n",
        "\t\t#print (time.time() - t)\n",
        "\t\t#print (black_l[-1])\n",
        "\n",
        "\t\tfor i in range(0, i1x):\n",
        "\t\t\tfor j in range(0, i1y):\n",
        "\t\t\t\ttry:\n",
        "\t\t\t\t\tif(np.array_equal(leftImage[j,i],np.array([0,0,0])) and  np.array_equal(warpedImage[j,i],np.array([0,0,0]))):\n",
        "\t\t\t\t\t\t# print \"BLACK\"\n",
        "\t\t\t\t\t\t# instead of just putting it with black, \n",
        "\t\t\t\t\t\t# take average of all nearby values and avg it.\n",
        "\t\t\t\t\t\twarpedImage[j,i] = [0, 0, 0]\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\tif(np.array_equal(warpedImage[j,i],[0,0,0])):\n",
        "\t\t\t\t\t\t\t# print \"PIXEL\"\n",
        "\t\t\t\t\t\t\twarpedImage[j,i] = leftImage[j,i]\n",
        "\t\t\t\t\t\telse:\n",
        "\t\t\t\t\t\t\tif not np.array_equal(leftImage[j,i], [0,0,0]):\n",
        "\t\t\t\t\t\t\t\tbw, gw, rw = warpedImage[j,i]\n",
        "\t\t\t\t\t\t\t\tbl,gl,rl = leftImage[j,i]\n",
        "\t\t\t\t\t\t\t\t# b = (bl+bw)/2\n",
        "\t\t\t\t\t\t\t\t# g = (gl+gw)/2\n",
        "\t\t\t\t\t\t\t\t# r = (rl+rw)/2\n",
        "\t\t\t\t\t\t\t\twarpedImage[j, i] = [bl,gl,rl]\n",
        "\t\t\t\texcept:\n",
        "\t\t\t\t\tpass\n",
        "\t\t# cv2.imshow(\"waRPED mix\", warpedImage)\n",
        "\t\t# cv2.waitKey()\n",
        "\t\treturn warpedImage\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrfJSvbWNOqh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == '__main__':\n",
        "\targs = \"/content/drive/My Drive/Colab Notebooks/txtlists/file4.txt\"\n",
        "\ts = Stitch(args)\n",
        "\ts.leftshift()\n",
        "\t# s.showImage('left')\n",
        "\ts.rightshift()\n",
        "\t#print \"done\"\n",
        "\tcv2.imwrite(\"test12.jpg\", s.leftImage)\n",
        "\t#print \"image written\"\n",
        "\t#cv2.destroyAllWindows()\n",
        "\t"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}